{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "x12_U-Net_Gan02_Test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1LsZHtqCKrJgc5-lcJFocu9RCAodNWE28",
      "authorship_tag": "ABX9TyNZuODr8Wdy5h9htheI7Ckx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/founderlin/PaperReview1/blob/master/x12_U_Net_Gan02_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToABe2R4zP6q"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "from torch.optim import optimizer\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim, tensor\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6mXsZf1zWLQ"
      },
      "source": [
        "Set the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkM47gpSzmjn"
      },
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        # read images for training\n",
        "        self.data_path = data_path\n",
        "        self.imgs_path = glob.glob(os.path.join(data_path, 'image/*.png'))\n",
        "\n",
        "    def augment(self, image, flipCode):\n",
        "        # data enrichment using cv2.flip\n",
        "        flip = cv2.flip(image, flipCode)\n",
        "        return flip\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # generate path of each image via index\n",
        "        image_path = self.imgs_path[index]\n",
        "        # print(image_path)\n",
        "\n",
        "        # generate path of label\n",
        "        label_path = image_path.replace('image', 'label')\n",
        "\n",
        "        # read all images and labels\n",
        "        image = cv2.imread(image_path)\n",
        "        label = cv2.imread(label_path)\n",
        "\n",
        "        # convert RGB to one-channel (black and white)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        image = image.reshape(1, image.shape[0], image.shape[1])\n",
        "        label = label.reshape(1, label.shape[0], label.shape[1])\n",
        "\n",
        "        # process labels, switch 255 to 1\n",
        "        if label.max() > 1:\n",
        "            label = label / 255\n",
        "\n",
        "        # data enrichment\n",
        "        flipCode = random.choice([-1, 0, 1, 2])\n",
        "        if flipCode != 2:\n",
        "            image = self.augment(image, flipCode)\n",
        "            label = self.augment(label, flipCode)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        # get the size of data set\n",
        "        return len(self.imgs_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHBip8ja0KoD"
      },
      "source": [
        "Set the U-net part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzaA2Pu1z8Ia"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
        "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0W7hMAo0rDN"
      },
      "source": [
        "Set the U-net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdxIYSuZ0tMN"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256, bilinear)\n",
        "        self.up2 = Up(512, 128, bilinear)\n",
        "        self.up3 = Up(256, 64, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.view(x.size(0), 512)\n",
        "        output = self.model(x)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnBiGFm1u9K"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv27RmdG1xfS"
      },
      "source": [
        "def train_net(netG, netD, device, data_path, epochs=50, batch_size=4, lr=1e-5):\n",
        "    # 加载训练集\n",
        "    isbi_dataset = DataLoader(data_path)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "    \n",
        "\n",
        "    # 定义RMSprop算法\n",
        "    # optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
        "    # torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
        "    # optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-8, amsgrad=False)\n",
        "\n",
        "    optimizer_D = optim.RMSprop(netD.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
        "    optimizer_G = optim.RMSprop(netG.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
        "\n",
        "    # 定义Loss算法\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # best_loss统计，初始化为正无穷\n",
        "    best_loss = float('inf')\n",
        "    # 训练epochs次\n",
        "    for epoch in range(epochs):\n",
        "        # 训练模式\n",
        "        netG.train()\n",
        "        netD.train()\n",
        "\n",
        "        # 按照batch_size开始训练\n",
        "        for n, (real_image, real_label) in enumerate(train_loader):\n",
        "\n",
        "            # Data for training the discriminator\n",
        "            real_image = real_image.to(device=device, dtype=torch.float32)\n",
        "            real_label = real_label.to(device=device, dtype=torch.float32)\n",
        "            made_image = netG(real_image)\n",
        "            real_label_D = torch.ones((batch_size, 1, 512, 1)).to(device=device)\n",
        "            made_label_D = torch.zeros(batch_size, 1, 512, 1).to(device=device)\n",
        "\n",
        "            all_image = torch.cat((real_image, made_image))\n",
        "            all_label_D = torch.cat((real_label_D, made_label_D))\n",
        "\n",
        "            # Training the discriminator\n",
        "            netD.zero_grad()\n",
        "            out_netD = netD(all_image)\n",
        "            # print(out_netD.size(), all_label_D.size())\n",
        "            loss_D = criterion(out_netD, all_label_D)\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Training the generator\n",
        "            netG.zero_grad()\n",
        "            out_netD_made = netG(real_image)\n",
        "            loss_G = criterion(out_netD_made, real_label)\n",
        "\n",
        "            # 保存loss值最小的网络参数\n",
        "            if loss_G < best_loss:\n",
        "                best_loss = loss_G\n",
        "                torch.save(netG.state_dict(), '/content/drive/MyDrive/Unet GAN model/best_model_Gan02.pth')\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            if n == batch_size - 1:\n",
        "                # print(f\"Epoch: {epoch} Loss D.: {loss_D}\")\n",
        "                # print(f\"Epoch: {epoch} Loss G.: {loss_G}\")\n",
        "                print(f\"{loss_D}, {loss_G}\")\n",
        "            \n",
        "    #     if epoch%2==0:\n",
        "    #         save_n='/content/drive/MyDrive/Unet GAN model/' + str(epoch) + \"_model_GANA128.pth\"\n",
        "    #         torch.save(netG.state_dict(), save_n)\n",
        "\n",
        "    # save_final=\"/content/drive/MyDrive/Unet GAN model/last_model_GANA128.pth\"\n",
        "    # torch.save(netG.state_dict(), save_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86QbDHYVEtkK"
      },
      "source": [
        "\n",
        "# 选择设备，有cuda用cuda，没有就用cpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 加载网络，图片单通道1，分类为1。\n",
        "generator = UNet(n_channels=1, n_classes=1).to(device=device)\n",
        "discriminator = Discriminator().to(device=device).to(device=device)\n",
        "# 指定训练集地址，开始训练\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/dataA/train\"\n",
        "train_net(generator, discriminator, device, data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mf8yrqn6_qs"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh8MUNiV8XNB"
      },
      "source": [
        "    # 选择设备，有cuda用cuda，没有就用cpu\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # 加载网络，图片单通道，分类为1。\n",
        "    net = UNet(n_channels=1, n_classes=1)\n",
        "    # 将网络拷贝到deivce中\n",
        "    net.to(device=device)\n",
        "    # 加载模型参数\n",
        "    net.load_state_dict(torch.load('/content/drive/MyDrive/Unet GAN model/best_model_Gan02.pth', map_location=device))\n",
        "    # 测试模式\n",
        "    net.eval()\n",
        "    # 读取所有图片路径\n",
        "    tests_path = glob.glob('/content/drive/MyDrive/Colab Notebooks/dataA/Gan02/*.png')\n",
        "    # 遍历素有图片\n",
        "    for test_path in tests_path:\n",
        "        # 保存结果地址\n",
        "        save_res_path = test_path.split('.')[0] + '_res.png'\n",
        "        # 读取图片\n",
        "        img = cv2.imread(test_path)\n",
        "        # 转为灰度图\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        # 转为batch为1，通道为1，大小为512*512的数组\n",
        "        img = img.reshape(1, 1, img.shape[0], img.shape[1])\n",
        "        # 转为tensor\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        # img_tensor = transforms.functional.to_pil_image(img)\n",
        "        # img_tensor = transforms.functional.resize(img_tensor, 256)\n",
        "        # img_tensor = transforms.functional.to_tensor(img_tensor)\n",
        "\n",
        "        # 将tensor拷贝到device中，只用cpu就是拷贝到cpu中，用cuda就是拷贝到cuda中。\n",
        "        img_tensor = img_tensor.to(device=device, dtype=torch.float32)\n",
        "        # 预测\n",
        "        pred = net(img_tensor)\n",
        "        # 提取结果\n",
        "        pred = np.array(pred.data.cpu()[0])[0]\n",
        "        # 处理结果\n",
        "        pred[pred >= 0.5] = 255\n",
        "        pred[pred < 0.5] = 0\n",
        "        # 保存图片\n",
        "        cv2.imwrite(save_res_path, pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}